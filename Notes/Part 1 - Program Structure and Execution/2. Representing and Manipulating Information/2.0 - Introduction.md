### Core Idea
- Computers represent and manipulate two-valued signals (bits).
- Bits alone aren't meaningful, but groups of [[1.1 - Information is Bits + Context|bits + interpretation (context)]] let us represent numbers, characters, and more.

---
### 1. Why Binary?
- Machines store/process info more reliably using two-valued signals:
	- High/low voltage
	- Magnetic orientation
	- Presence/absence of a hole
	- Etc
- Hardware for binary logic is simple, fast, and scalable. --> Billions of circuits per chip.

---
### 2. Bit Patterns Represent Different Data
- Meaning depends on interpretation:
	- Unsigned integers
	- Two's-complement integers (signed)
	- Floating-point numbers
	- Character encodings
	- Etc

---
### 3. Three Major Number Representations
##### Unsigned
- Standard binary for non-negative integers.
##### Two's Complement
- Dominant representation for signed integers.
##### Floating-Point
- Base-2 scientific notation for real numbers.
- Encodes a wide range, but approximate.

---
### 4. Bit Limits --> Overflow & Weird Behaviours
- Fixed-size representations mean operations can overflow.
- Example:
	- `int` is typically 32-bit --> limited range.
	- `200 * 300 * 400 * 500` overflows to `-884,901,888`
##### Integer Arithmetic
- Precise, limited range.
- Still obeys many familiar properties (commutative, associative).
- Even though results can overflow, they're consistent.
##### Floating-point Arithmetic
- Approximate, wide range.
- Not associative, due to rounding:
	- `(3.14 + 1e20) - 1e20` --> `0.0`
	- `3.14 + (1e20 - 1e20)` --> `3.14`

---
### 5. Why We Study These Details
- To understand:
	- Value ranges
	- Overflow behaviour
	- Arithmetic properties
- Avoid bugs and security vulnerabilities caused by subtle numeric issues.
- Ensure portability across machines, OSes, and compilers.
